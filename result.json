{
  "Title": "Automated Program Repair in the Era of Large Pre-trained Language Models",
  "Outline": [
    {
      "Title": "Abstract",
      "Outline": "- 自动程序修复（APR）旨在帮助开发人员自动修复软件错误。\n- 当前APR技术存在修复方案种类有限的问题。\n- 经过数十亿Token训练的大语言模型（LLM）可能解决此问题。\n- 最近用于APR的LLM研究未使用最先进的模型或现实数据集。\n- 进行了第一次直接应用LLM于APR的广泛研究。\n  - 选择了包括生成式和填充模型在内的9个最新LLM。\n  - 模型大小从125M到20B不等。\n- 设计了3种LLM生成修复方案的设置。\n- 在跨3种语言的5个数据集上应用LLM。\n- 将LLM与彼此及最新APR工具进行比较。\n- 发现LLM在所有数据集上显著优于现有APR技术。\n  - 更大的LLM通常表现更好。\n  - 修复行后的代码对生成可编译修复方案很重要。\n- LLM能够识别正确的修复方案并有助于排名或正确性检查。\n- 通过增加样本量和整合修复模板信息可以进一步显著提升基于LLM的APR性能。\n"
    },
    {
      "Title": "INTRODUCTION",
      "Outline": "- 软件缺陷可能导致安全问题和财务损失。\n- 开发了自动化程序修复（APR）工具以减少手动修复工作。\n- 基于模板的APR，受限于修复模板，被广泛认可。\n- 基于学习的APR工具，使用神经机器翻译，需要监督数据集。\n- 大语言模型（LLM）为APR提供了不依赖历史错误修复的替代方案。\n- AlphaRepair使用CodeBERT进行APR，无需微调即展示了最新成果。\n- 研究利用Codex进行生成式APR，但仅在小规模简单数据集上评估。\n- LLMs在代码任务上进行评估，但评估指标未能反映代码的功能性或语义正确性。\n- 本项工作在三种APR环境中评估最新LLMs修复真实世界项目的能力。\n- 研究比较了LLMs，并在多种数据集和语言上包含了填空式和生成式APR。\n- 论文展示了LLMs在APR中的潜力，并提供了一个现实的评估场景。\n- 研究表明LLMs在APR上大幅超越现有工具，更大模型提供更强的APR结果。\n- 强调了后缀代码的重要性、修复方案的自然性，以及LLM基础上APR的潜在改进点。\n"
    },
    {
      "Title": "BACKGROUND AND RELATED WORK",
      "Outline": "- 大语言模型(LLMs)：在NLP任务中无需微调即可取得卓越性能；利用prompt engineering。\n- 大语言模型(LLMs)：根据架构分为encoder-only、decoder-only和encoder-decoder模型；具有不同架构和目标。\n- Encoder-only模型：学习表示，用MLM目标训练。\n- Decoder-only模型：生成式，预测下一个Token。\n- Encoder-decoder模型：序列到序列任务，跨度预测训练。\n- 自动程序修复(APR)工具：生成补丁，针对测试套件进行验证。\n- 传统APR工具：基于启发式、基于约束、基于模板；基于模板的表现最佳。\n- 基于学习的APR工具：需要修复数据；修复类型有限。\n- AlphaRepair：zero-shot设置，使用CodeBERT进行修复。\n- 最近研究：应用LLMs进行APR；Codex显示出竞争性结果；更大的LLMs改善修复结果。\n- 研究：利用各种LLMs和熵进行补丁排名和正确性检查。\n"
    },
    {
      "Title": "APPROACH",
      "Outline": "- 选定基于 Hugging Face 受欢迎程度和包含代码的训练数据的 LLM 进行 APR 评估。\n- LLM 范围：125M 到 20B 参数。\n- 生成模型：GPT-Neo, GPT-J, GPT-NeoX，在 The Pile 上训练，部分包含 Github 代码。\n- Codex：12B 参数模型，在大量代码文件上微调。\n- 填空模型：CodeT5 和 INCODER，在 Github/GitLab 代码和 StackOverFlow 数据上训练。\n- 三种 APR 设置：完整函数生成，正确代码填空，单行生成。\n- 完整函数生成使用提示进行 few-shot 学习。\n- 正确代码填空使用错误代码周围的前缀和后缀。\n- 单行生成允许直接比较填空和生成模型。\n- 补丁排名使用熵来优先考虑可能正确的补丁。\n- 补丁根据测试套件的正确性进行验证。\n"
    },
    {
      "Title": "EXPERIMENTAL SETUP",
      "Outline": "- RQ1：研究大语言模型在不同自动程序修复（APR）设置中的表现，包括不同数据集、语言、任务、模型大小、计算时间和编译率。\n- RQ2：将大语言模型直接应用于APR的结果与最新的APR工具进行比较，重点是大语言模型修复的独特错误和优势。\n- RQ3：研究是否可以直接利用大语言模型进行补丁排名和正确性检查，使用内置度量。\n- RQ4：探索通过增加样本数量和结合模板来提高大语言模型在APR性能上的表现。\n- 在Python和PyTorch中实现生成管道，使用Hugging Face和OpenAI的Codex API。\n- 在3种编程语言的5个APR基准上进行评估，专注于单函数修复。\n- 与20个APR工具进行比较，使用完美故障定位进行公平比较。\n- 使用可能的和正确的补丁作为评估指标，并进行手动检查以确定正确性。\n"
    },
    {
      "Title": "RESULT",
      "Outline": "- 大语言模型修复效果随模型大小增加而提高。\n- Codex 12B 在代码生成方面的专注使其优于 GPT-NeoX 20B。\n- 代码填充和单行生成的正确修复比率高于完整函数生成。\n- Codex 在代码填充方面的表现优于函数生成。\n- 填充模型在修复方面超越生成模型。\n- 更大的大语言模型拥有更慢的补丁生成速度。\n- Codex 和 INCODER 提出了独特的错误修复。\n- 大语言模型可超越最先进的自动程序修复工具。\n- 大语言模型在多语言修复方面显示出潜力。\n- 正确的补丁的熵低于非合理的补丁。\n- 熵可以帮助进行补丁正确性检查。\n- 使用熵进行补丁排名证明是有效的。\n- INCODER 结合模板提高了自动程序修复的性能。\n"
    },
    {
      "Title": "THREATS TO VALIDITY",
      "Outline": "- 手动验证补丁引入内部威胁，通过公开补丁和代码解决。\n- 通过检查Defects4J 1.2的补丁来解决潜在的数据泄露问题；66%的修复与开发者补丁不同；排除单行错误后，比率提高到77%。\n- 85%的LLM可修复的错误与原始开发者补丁不同；去掉重复的修复仍可解决问题。\n- 大多数正确的LLM补丁并非来自训练数据记忆；只有15%的相同补丁在训练数据中找到。\n- 结合修复模板和LLM可以提升结果；与数据泄露问题正交。\n- LLM在不在训练数据中的QuixBugs数据集上达到了最先进水平；减少数据泄露需要代价高昂的重新训练。\n- 在5个数据集和3种编程语言上的评估全面，但可能无法推广到其他数据集或语言。\n"
    },
    {
      "Title": "DISCUSSION AND FUTURE WORK",
      "Outline": "- 对大语言模型应用于软件工程中的自动程序修复（APR）进行大规模研究。\n- 展示大语言模型已经超越了现有的APR技术。\n- 结合软件工程特定技术以提高大语言模型性能。\n- 未来工作：\n  - 利用项目特定和修复特定知识改进大语言模型在APR中的性能。\n  - 探索新类型的大语言模型如ChatGPT在APR中的应用。\n- 将大语言模型应用于其他软件工程任务：\n  - 使用大语言模型进行模糊测试以产生测试输入。\n  - 将大语言模型应用于上下文依赖的任务，如测试生成。\n  - 在变异测试和缺陷播种中使用大语言模型。\n- 大语言模型在软件工程各种代码生成/变异任务中的潜力。\n"
    },
    {
      "Title": "CONCLUSION",
      "Outline": "- 评估9个最先进的大语言模型与5个修复数据集在不同修复设置中的表现。\n- 研究模型大小对自动程序修复 (APR) 关键因素的影响：修复的bug数量、补丁生成速度和编译率。\n- 将大语言模型与最先进的APR工具进行比较，强调使用大语言模型进行APR的独特修复和优势。\n- 评估大语言模型进行补丁排名和正确性检查的能力，以优先修复正确的补丁。\n- 探索提高大语言模型在APR性能的方法：增加样本量、结合修复模板。\n- 提出使用大语言模型在APR及其他软件工程(SE)程序生成/变异任务中有希望的未来。\n"
    }
  ]
}